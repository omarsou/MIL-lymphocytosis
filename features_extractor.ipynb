{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T00:00:47.796128Z",
     "start_time": "2021-03-12T00:00:47.792154Z"
    }
   },
   "outputs": [],
   "source": [
    "from features_extractor import *\n",
    "import torchvision.transforms as transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Locally (to speed up things)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
    "from google.colab import files\n",
    "# Here you should upload your Kaggle API key (see : https://www.kaggle.com/docs/api (Authentification paragraph))\n",
    "files.upload()\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets list\n",
    "! kaggle competitions download -c 3md3070-dlmi\n",
    "! unzip /content/3md3070-dlmi.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/DLMI_Challenge/clinical_data_clean.csv\")\n",
    "train_df = df[df.LABEL > -0.5]\n",
    "test_df = df[df.LABEL < -0.5]\n",
    "\n",
    "train_path = []\n",
    "for name in train_df.ID:\n",
    "    listfiles = os.listdir('/content/trainset/' + name)\n",
    "    train_path += ['/content/trainset/' + name + '/' + img_name for img_name in listfiles]\n",
    "test_path = []\n",
    "for name in test_df.ID:\n",
    "    listfiles = os.listdir('/content/testset/' + name)\n",
    "    test_path += ['/content/testset/' + name + '/' + img_name for img_name in listfiles]\n",
    "all_path = train_path + test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_size = 224        # EfficientNet image size\n",
    "\n",
    "# training parameters\n",
    "epochs = 80        # training epochs\n",
    "batch_size = 16\n",
    "learning_rate = 0.002\n",
    "log_interval = 10   # interval for displaying training info\n",
    "\n",
    "# save model\n",
    "save_model_path = '/content/drive/MyDrive/DLMI_Challenge/'\n",
    "\n",
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([transforms.Resize(res_size),\n",
    "                                MyRotateTransform([0, 90, 180, 0, 270, 360, 0]),\n",
    "                                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                transforms.RandomVerticalFlip(p=0.5),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "data = LymphoDataset(all_path, transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=data, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model To Device\n",
    "lympho_AE = LymphoAutoEncoder().to(device)\n",
    "# Initialize Optimizer\n",
    "model_params = list(lympho_AE.parameters())\n",
    "optimizer = torch.optim.Adam(model_params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Training\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "best = np.inf\n",
    "# start training\n",
    "for epoch in range(epochs):\n",
    "    # train, test model\n",
    "    train_losses = train(50, resnet_vae, device, data_loader, optimizer, epoch, criterion, best, save_model_path)\n",
    "    err = sum(train_losses)/len(train_losses)\n",
    "    if err < best:\n",
    "        best = err\n",
    "    print(f\"Epoch : {epoch} , Mean Error : {sum(train_losses)/len(train_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "lympho_AE = LymphoAutoEncoder()\n",
    "lympho_AE.load_state_dict(torch.load(\"/content/drive/MyDrive/DLMI_Challenge/model_vae_efficient.pth\"))\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "lympho_AE.to(device)\n",
    "\n",
    "# Mode Eval\n",
    "lympho_AE.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/DLMI_Challenge/clinical_data_clean.csv\")\n",
    "# Normalize\n",
    "df.loc[:, ['LYMPH_COUNT', 'AGE']] = (df[['LYMPH_COUNT', 'AGE']] - df[['LYMPH_COUNT', 'AGE']].min())/(df[['LYMPH_COUNT', 'AGE']].max() - df[['LYMPH_COUNT', 'AGE']].min())\n",
    "# Separate train & test\n",
    "train_df = df[df.LABEL > -0.5].reset_index(drop=True)\n",
    "test_df = df[df.LABEL < -0.5].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = []\n",
    "names_file = []\n",
    "for name in train_df.ID:\n",
    "    listfiles = os.listdir('/content/trainset/' + name)\n",
    "    train_path += ['/content/trainset/' + name + '/' + img_name for img_name in listfiles]\n",
    "    names_file += [name]*len(listfiles)\n",
    "\n",
    "horizontal_flip = [key + '_horizontal' for key in train_df.ID]\n",
    "vertical_flip = [key + '_vertical' for key in train_df.ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to store everything\n",
    "train_data = {k: {'features': [], 'features_reduced': []} for k in train_df.ID.tolist() + horizontal_flip + vertical_flip}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Picture (no data augmentation)\n",
    "res_size = 224\n",
    "transform = transforms.Compose([transforms.Resize(res_size),\n",
    "                                transforms.ToTensor()])\n",
    "Train = InferLymphoDataset(train_path, names_file, transform)\n",
    "data_loader = DataLoader(dataset=Train, batch_size=10, shuffle=False, num_workers=8)\n",
    "for batch_idx, (X, names) in tqdm(enumerate(data_loader)):\n",
    "    # distribute data to device\n",
    "    X  = X.to(device)\n",
    "    _ , pooled_reduced, pooled = lympho_AE(X)\n",
    "    pooled = pooled.detach().cpu()\n",
    "    pooled_reduced = pooled_reduced.detach().cpu()\n",
    "    for idx, name in enumerate(names[0]):\n",
    "        train_data[name]['features'].append(pooled[idx].squeeze(1).reshape(1,-1))\n",
    "        train_data[name]['features_reduced'].append(pooled_reduced[idx].squeeze(1).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picture being fliped horizontally\n",
    "transform = transforms.Compose([transforms.Resize(res_size),\n",
    "                                transforms.RandomHorizontalFlip(p=1.0),\n",
    "                                transforms.ToTensor()])\n",
    "train = InferLymphoDataset(train_path, names_file, transform)\n",
    "data_train = DataLoader(dataset=train, batch_size=10, shuffle=False, num_workers=8)\n",
    "for batch_idx, (X, names) in tqdm(enumerate(data_train)):\n",
    "    # distribute data to device\n",
    "    X  = X.to(device)\n",
    "    _ , pooled_reduced, pooled = lympho_AE(X)\n",
    "    pooled = pooled.detach().cpu()\n",
    "    pooled_reduced = pooled_reduced.detach().cpu()\n",
    "    for idx, name in enumerate(names[0]):\n",
    "        train_data[name + '_horizontal']['features'].append(pooled[idx].squeeze(1).reshape(1,-1))\n",
    "        train_data[name + '_horizontal']['features_reduced'].append(pooled_reduced[idx].squeeze(1).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picture Being Fliped Vertically\n",
    "transform = transforms.Compose([transforms.Resize(res_size),\n",
    "                                transforms.RandomVerticalFlip(p=1.0),\n",
    "                                transforms.ToTensor()])\n",
    "Train = InferLymphoDataset(train_path, names_file, transform)\n",
    "data_loader = DataLoader(dataset=Train, batch_size=10, shuffle=False, num_workers=8)\n",
    "for batch_idx, (X, names) in tqdm(enumerate(data_loader)):\n",
    "    # distribute data to device\n",
    "    X  = X.to(device)\n",
    "    _ , pooled_reduced, pooled = lympho_AE(X)\n",
    "    pooled = pooled.detach().cpu()\n",
    "    pooled_reduced = pooled_reduced.detach().cpu()\n",
    "    for idx, name in enumerate(names[0]):\n",
    "        train_data[name + '_vertical']['features'].append(pooled[idx].squeeze(1).reshape(1,-1))\n",
    "        train_data[name + '_vertical']['features_reduced'].append(pooled_reduced[idx].squeeze(1).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate features of the same patient\n",
    "for key in train_data.keys():\n",
    "    train_data[key]['features'] = torch.cat(train_data[key]['features'], dim=0)\n",
    "    train_data[key]['features_reduced'] = torch.cat(train_data[key]['features_reduced'], dim=0)\n",
    "\n",
    "# Add all data (age, label, concentration)\n",
    "for idx, row in train_df.iterrows():\n",
    "    key = row['ID']\n",
    "    train_data[key]['label'] = torch.as_tensor([row['LABEL']], dtype=torch.int64)\n",
    "    train_data[key]['age'] = torch.as_tensor([row['AGE']], dtype=torch.float32)\n",
    "    train_data[key]['concentration'] = torch.as_tensor([row['LYMPH_COUNT']], dtype=torch.float32)\n",
    "    train_data[key + '_horizontal']['label'] = torch.as_tensor([row['LABEL']], dtype=torch.int64)\n",
    "    train_data[key + '_horizontal']['age'] = torch.as_tensor([row['AGE']], dtype=torch.float32)\n",
    "    train_data[key + '_horizontal']['concentration'] = torch.as_tensor([row['LYMPH_COUNT']], dtype=torch.float32)\n",
    "    train_data[key + '_vertical']['label'] = torch.as_tensor([row['LABEL']], dtype=torch.int64)\n",
    "    train_data[key + '_vertical']['age'] = torch.as_tensor([row['AGE']], dtype=torch.float32)\n",
    "    train_data[key + '_vertical']['concentration'] = torch.as_tensor([row['LYMPH_COUNT']], dtype=torch.float32)\n",
    "    \n",
    "# save\n",
    "save(train_data, \"/content/drive/MyDrive/DLMI_Challenge/data/files_efficient.train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = []\n",
    "names_file = []\n",
    "for name in test_df.ID:\n",
    "    listfiles = os.listdir('/content/testset/' + name)\n",
    "    test_path += ['/content/testset/' + name + '/' + img_name for img_name in listfiles]\n",
    "    names_file += [name]*len(listfiles)\n",
    "    \n",
    "horizontal_flip = [key + '_horizontal' for key in test_df.ID]\n",
    "vertical_flip = [key + '_vertical' for key in test_df.ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to store everything\n",
    "test_data = {k: {'features': [], 'features_reduced': []} for k in test_df.ID.tolist() + horizontal_flip + vertical_flip}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Picture\n",
    "res_size = 224\n",
    "transform = transforms.Compose([transforms.Resize(res_size),\n",
    "                                transforms.ToTensor()])\n",
    "Test = InferLymphoDataset(test_path, names_file, transform)\n",
    "data_loader = DataLoader(dataset=Test, batch_size=10, shuffle=False, num_workers=8)\n",
    "for batch_idx, (X, names) in tqdm(enumerate(data_loader)):\n",
    "    # distribute data to device\n",
    "    X  = X.to(device)\n",
    "    _ , pooled_reduced, pooled = lympho_AE(X)\n",
    "    pooled = pooled.detach().cpu()\n",
    "    pooled_reduced = pooled_reduced.detach().cpu()\n",
    "    for idx, name in enumerate(names[0]):\n",
    "        test_data[name]['features'].append(pooled[idx].squeeze(1).reshape(1,-1))\n",
    "        test_data[name]['features_reduced'].append(pooled_reduced[idx].squeeze(1).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal Picture\n",
    "transform = transforms.Compose([transforms.Resize(res_size),\n",
    "                                transforms.RandomHorizontalFlip(p=1.0),\n",
    "                                transforms.ToTensor()])\n",
    "Test = InferLymphoDataset(test_path, names_file, transform)\n",
    "data_loader = DataLoader(dataset=Test, batch_size=10, shuffle=False, num_workers=8)\n",
    "for batch_idx, (X, names) in tqdm(enumerate(data_loader)):\n",
    "    # distribute data to device\n",
    "    X  = X.to(device)\n",
    "    _ , pooled_reduced, pooled = lympho_AE(X)\n",
    "    pooled = pooled.detach().cpu()\n",
    "    pooled_reduced = pooled_reduced.detach().cpu()\n",
    "    for idx, name in enumerate(names[0]):\n",
    "        test_data[name + '_horizontal']['features'].append(pooled[idx].squeeze(1).reshape(1,-1))\n",
    "        test_data[name + '_horizontal']['features_reduced'].append(pooled_reduced[idx].squeeze(1).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical Picture\n",
    "transform = transforms.Compose([transforms.Resize(res_size),\n",
    "                                transforms.RandomVerticalFlip(p=1.0),\n",
    "                                transforms.ToTensor()])\n",
    "Test = InferLymphoDataset(test_path, names_file, transform)\n",
    "data_loader = DataLoader(dataset=Test, batch_size=10, shuffle=False, num_workers=8)\n",
    "for batch_idx, (X, names) in tqdm(enumerate(data_loader)):\n",
    "    # distribute data to device\n",
    "    X  = X.to(device)\n",
    "    _ , pooled_reduced, pooled = lympho_AE(X)\n",
    "    pooled = pooled.detach().cpu()\n",
    "    pooled_reduced = pooled_reduced.detach().cpu()\n",
    "    for idx, name in enumerate(names[0]):\n",
    "        test_data[name + '_vertical']['features'].append(pooled[idx].squeeze(1).reshape(1,-1))\n",
    "        test_data[name + '_vertical']['features_reduced'].append(pooled_reduced[idx].squeeze(1).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in test_data.keys():\n",
    "    test_data[key]['features'] = torch.cat(test_data[key]['features'], dim=0)\n",
    "    test_data[key]['features_reduced'] = torch.cat(test_data[key]['features_reduced'], dim=0)\n",
    "    \n",
    "for idx, row in test_df.iterrows():\n",
    "    key = row['ID']\n",
    "    test_data[key]['label'] = torch.as_tensor([row['LABEL']], dtype=torch.int64)\n",
    "    test_data[key]['age'] = torch.as_tensor([row['AGE']], dtype=torch.float32)\n",
    "    test_data[key]['concentration'] = torch.as_tensor([row['LYMPH_COUNT']], dtype=torch.float32)\n",
    "    test_data[key + '_horizontal']['label'] = torch.as_tensor([row['LABEL']], dtype=torch.int64)\n",
    "    test_data[key + '_horizontal']['age'] = torch.as_tensor([row['AGE']], dtype=torch.float32)\n",
    "    test_data[key + '_horizontal']['concentration'] = torch.as_tensor([row['LYMPH_COUNT']], dtype=torch.float32)\n",
    "    test_data[key + '_vertical']['label'] = torch.as_tensor([row['LABEL']], dtype=torch.int64)\n",
    "    test_data[key + '_vertical']['age'] = torch.as_tensor([row['AGE']], dtype=torch.float32)\n",
    "    test_data[key + '_vertical']['concentration'] = torch.as_tensor([row['LYMPH_COUNT']], dtype=torch.float32)\n",
    "    \n",
    "save(test_data, \"/content/drive/MyDrive/DLMI_Challenge/data/files_efficient.test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
